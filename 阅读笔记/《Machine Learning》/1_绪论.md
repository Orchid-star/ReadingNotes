**机器学习**

机器学习研究如果根据已有的经验数据产生模型，从而获得对非经验数据的处理能力（即预测能力）。



**模型**：从数据中学习的结果（简单理解为一个可接收输入并给出对应数据的函数）

**样本**：若干属性以及对应的属性值的集合，是对单一事物的记录或描述。

**数据集**：样本（或称为记录、示例等）的集合。

**属性空间、样本空间、输入空间**：样本各属性张成的空间。（每一个属性各自对应一根坐标轴）。

**特征向量（feature vector）**：每个样本在样本空间中都对应一个点，点对应一个坐标向量。一个样本就是一个特征向量。

**假设（hypothesis)**：即模型，对应的是关于数据的某种潜在规律。

**真相、真实（ground-truth)**：数据的规律。

**学习、训练、学习过程**：为了找出或逼近真相，从数据中学得模型的过程。

**学习器（learner)**：即模型，是学习算法在给定数据和参数空间上的实例化。

**标记、标签（label)**：示例或样本的“结果”信息。

**样例（example)：**拥有标记信息的示例或样本，称为“样例”。（**x**~i~，y~i~)

**标记空间（label space)、输出空间**：所有标记的集合。



**分类（classification）**：预测值是离散值的学习任务称为分类。

**二分类（binary classification)**：只涉及两个类别的学习任务称。两个类别通常称为*正类（positive class)*和*反类（negative class)*。

**多分类（multi-class classification)**：涉及多个类别的分类任务。

**回归（regression）**：预测值是连续值的的学习



**预测任务**：通过对训练集{ (**x**~1~, y~1~)， (**x**~2~, y~2~)，... ，(**x**~m~, y~m~) }进行学习，建立一个从输入空间**X**到输出空间**Y**的映射*f :**X** -> Y*。对二分类任务，通常令Y = {-1，+1}或{0，1}，对多分类任务，|Y| > 2；对回归任务，Y = R，即实数集。

**测试（testing）**：对学得的模型进行预测的过程。

**测试样本（testing sample）**：测试过程中被预测的样本。

**预测标记**：模型对测试例的预测结果。区别于真实标记。例如学得模型*f*，对测试例*x*，可得预测标记*y = f(x)*。

**聚类（clustering）**：将训练集中的样本分成若干组，每组称为一个簇（cluster）。

**监督学习（supervised learning)、无监督学习（unsupervised learning)**：根据训练数据是否有标记信息，分成监督学习和非监督学习。分类和回归是监督学习的代表，聚类是非监督学习的代表。



**泛化（generalization)能力**：学得的模型适用于新样本的能力，称为泛化能力。机器学习的目标是使学得的模型能很好地适用于新样本，即适应整个样本空间。

**独立同分布（independent and identically distributed)**：尽管训练集通常只是样本空间的一个很小的采样，但是仍然希望训练集能够很好的反应整个样本空间的特性。所以通常假设样本空间中全体样本服从一个未知*分布（distribution)*,我们获得的每个样本都是独立地从这个分布上采样获得的，这就称为*独立同分布*。

**为什么采样做到独立同分布？**

*独立同分布*中的”同“指的是样本集与样本空间满足同一分布。

模型是通过学习样本集得到的，反应的是样本集的特性，只有样本集的特性与整个样本空间的特性一致，才能认为习得的模型反应了样本空间的特性。不独立，意味着采样数据有偏好，采样集与实际分布不符。

举个例子：假设一个分布是*p(x1) = 0.1, p(x2) = 0.7, p(x3) = 0.2*, 如果样本集中*x1、x2、x3*出现的频率分别是*0.5、0.1、0.4*，那么习得模型在输入*x1*预测其概率时，输出一定会更接近训练集中的*0.5*，而不是实际的*0.1*。这就是采集的样本一定要独立的原因，只有独立才能体现样本空间的特征。

